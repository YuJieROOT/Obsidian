![[Ch1 神经网络 & pytorch/【G】用 pytorch 构建一个模型 (nn.Module).md#^frame=Gbb4SaWONZKNdzsMAQEus|定义模型]]
这段代码定义了一个简单的神经网络 `SimpleNet`，它继承自 `torch.nn.Module`，这是 PyTorch 中**所有神经网络模型的基类**。

1. **导入所需模块**：
    
    ```python
    import torch.nn as nn
    ```
    
    这行代码导入了 PyTorch 的 `torch.nn` 模块，并简化为 `nn`。该模块包含了用于构建神经网络的常用组件，如层（`Layer`）、激活函数（`Activation`）等。
    
2. **定义神经网络模型**：
    
    ```python
    class SimpleNet(nn.Module):
    ```
    
    这行代码定义了一个名为 `SimpleNet` 的类，继承自 `nn.Module`，表明它是一个神经网络模型。
    
3. **初始化模型的层**：
    
    ```python
    def __init__(self):
        super(SimpleNet, self).__init__()
        self.fc1 = nn.Linear(784, 256)  # 输入层到隐藏层
        self.fc2 = nn.Linear(256, 10)   # 隐藏层到输出层
    ```
    
    在 `__init__` 方法中：
    
    - `super(SimpleNet, self).__init__()`：调用父类 `nn.Module` 的初始化方法，确保继承关系正常。
    - `self.fc1 = nn.Linear(784, 256)`：定义一个**全连接层**，将输入数据从 784 维（例如一个 28x28 的图像，展平后的长度）映射到 256 维的隐藏层。
    - `self.fc2 = nn.Linear(256, 10)`：定义另一个全连接层，将 256 维的隐藏层输出映射到 10 维的输出层（通常用于分类任务，例如 10 类输出）。
4. **前向传播函数**：
    
    ```python
    def forward(self, x):
        x = torch.relu(self.fc1(x))
        x = self.fc2(x)
        return x
    ```
    
    - `forward` 方法定义了神经网络的前向传播过程。
    - `x = torch.relu(self.fc1(x))`：将输入 `x` 传入 `fc1` 层，并应用 ReLU 激活函数。<mark style="background: #FF5582A6;">ReLU（Rectified Linear Unit）将输入值小于零的部分设置为 0，其余部分保持不变。</mark>
    - `x = self.fc2(x)`：将经过 ReLU 激活后的结果传入第二个全连接层 `fc2`。
    - `return x`：返回最终的输出结果。
5. **创建模型实例**：
    
    ```python
    model = SimpleNet()
    ```
    
    这行代码创建了 `SimpleNet` 类的一个实例 `model`，表示该神经网络模型可以用来进行训练或推理。
    

### 总结：

这个模型有**两个全连接层**（`fc1` 和 `fc2`），用于处理 784 维输入（可能是展平后的图像数据）并输出一个 10 维的向量（可能是分类的概率分布）。其中，第一个全连接层使用 ReLU 激活函数来**增加非线性**。
